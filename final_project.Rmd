---
title: "final_project"
author: "Yu He"
date: "2023-03-13"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Overview of dataset: The Youth Risk Behavior Surveillance System (YRBSS) 2019 high school data for all states

The Youth Risk Behavior Surveillance System (YRBSS) monitors six categories of health-related behaviors that contribute to the leading causes of death and disability among youth and adults, including—

* Behaviors that contribute to unintentional injuries and violence
* Sexual behaviors related to unintended pregnancy and sexually transmitted diseases, including HIV infection
* Alcohol and other drug use
* Tobacco use
* Unhealthy dietary behaviors
* Inadequate physical activity

Database website: https://www.cdc.gov/healthyyouth/data/yrbs/index.htm

Codebook for variable included in the dataset -

* sitename - Name of location covered by a survey
* year - 4-digit year of survey – 1991, 1993, etc
* weight - Analytical weight – used in statistical analyses
* age - Data from:
    How old are you?
    A. 12 years old or younger
    B. 13 years old
    C. 14 years old
    D. 15 years old
    E. 16 years old
    F. 17 years old
    G. 18 years old or older
* sex - Data from:
    What is your sex?
    A. Female
    B. Male
* grade - Data from:
    In what grade are you?
    A. 9th grade
    B. 10th grade
    C. 11th grade
    D. 12th grade
    E. Ungraded or other grade
* race4 - 4-level variable from race and ethnicity questions:
    1 = “White”
    2 = “Black or African American”
    3 = “Hispanic/Latino”
    4 = “All Other Races”
* race7 - 7-level variable from race and ethnicity questions:
    1 = “American Indian/Alaska Native”
    2 = “Asian”
    3 = “Black or African American”
    4 = “Hispanic/Latino”
    5 = “Native Hawaiian/Other Pacific Islander”
    6 = “White”
    7 = “Multiple Races (Non-Hispanic)”
* stheight - Data from:
    How tall are you without your shoes on?
* bmi - Body mass index (BMI)
* bmipct - Student’s BMI percentile
* qnobese - 
    1 = obese (when BMI percentile is at or
    above the 95th percentile for BMI by age and sex)
    2 = No
* sexid - Sexual identity:
    1 = "Heterosexual"
    2 = "Gay or Lesbian"
    3 = "Bisexual"
    4 = "Not Sure"
* qnfrcig - Currently smoked cigarettes frequently
    1 = Yes
    2 = No
* qnothhpl - Used birth control pills; an IUD (such as Mirena or
    ParaGard) or implant (such as Implanon or
    Nexplanon); or a shot (such as Depo-Provera), patch
    (such as OrthoEvra), or birth control ring (such as
    NuvaRing) before last sexual intercourse
    1 = Yes
    2 = No
* qfoodallergy - Food allergies
    1 = Yes
    2 = No
    3 = Not sure
* qncurrentasthma - Current asthma
    1 = Yes
    2 = No
    3 = Not sure
* qncurrentopioid - Currently took prescription pain medicine without a
    doctor's prescription or differently than how a doctor
    told them to use it
    
## load libraries
```{r}
library(tidyverse)
library(haven)
library(caret)
library(rpart)
library(rpart.plot)
library(pROC)
library(e1071)
```


## Step 1, data import and process, save the processed sas7dbat data into csv file to improve R runnig time. Only run one time.
```{r}
# set path
setwd("~/Desktop/CU Spring 2023/P8451 intro to machine learning for EPI/p8451_final_project")

# load state data a_m
#df_a_m = read_sas("sadc_2019_state_a_m.sas7bdat") %>% 
#  janitor::clean_names() %>% 
#  select(sitename, year, weight, age, sex, grade, race4, race7, stheight, bmi, bmipct, qnobese, sexid, qnfrcig, 
#         qnothhpl, qfoodallergy, qncurrentasthma, qncurrentopioid)

# save the data as a CSV file
# write.csv(df_a_m, "df_a_m.csv", row.names = FALSE)

# load state data n_z
#df_n_z = read_sas("sadc_2019_state_n_z.sas7bdat") %>% 
#  janitor::clean_names() %>% 
#    select(sitename, year, weight, age, sex, grade, race4, race7, stheight, bmi, bmipct, qnobese, sexid, qnfrcig, 
#         qnothhpl, qfoodallergy, qncurrentasthma, qncurrentopioid)

# save the data as a CSV file
#write.csv(df_n_z, "df_n_z.csv", row.names = FALSE)
```

## assess the pattern of missing variables
```{r}
# load the processed data
df_part1 = read_csv("df_a_m.csv")
df_part2 = read_csv("df_n_z.csv")

# merge two dataset
df_f_project = bind_rows(df_part1, df_part2)
```

```{r}
# find the number of missing observation in each variables in df_f_project
colSums(is.na(df_f_project))

# find the proportion of missing observation in each variables in df_f_project
colMeans(is.na(df_f_project))

summary(df_f_project)
```

## create new variables and data cleaning
```{r}
# 
df_fit <- 
  df_f_project %>% 
  filter(year == 2019) %>% 
  mutate(
    # create new variable for missing analysis
    missing_sexid = ifelse(is.na(sexid), 1, 0),
    missing_qnothhpl = ifelse(is.na(qnothhpl), 1, 0),
    missing_qfoodallergy = ifelse(is.na(qfoodallergy), 1, 0),
    missing_qncurrentasthma = ifelse(is.na(qncurrentasthma), 1, 0),
    missing_qncurrentopioid = ifelse(is.na(qncurrentopioid), 1, 0),
    # convert variables into factors
    across(c("age", "sex", "grade", "race4", "race7", "qnobese", "qnfrcig", "missing_sexid", "missing_qnothhpl", 
             "missing_qfoodallergy", "missing_qncurrentasthma", "missing_qncurrentopioid"), as.factor
           )
    ) %>% 
  select(-c(sitename, year, sexid, qnothhpl, qfoodallergy, qncurrentasthma, qncurrentopioid)) %>% 
  na.omit() 
  
# find the number of missing observation in each variables in df_fit
colSums(is.na(df_fit))

# find the proportion of missing observation in each variables in df_fit
colMeans(is.na(df_fit))

# check the balance of df_fit, the outcome variable if missing_sexid
summary(df_fit)

```


## Step 3, Partition data into training and testing sets

```{r}
set.seed(123)
training_data <- df_fit$missing_sexid %>% createDataPartition(p = 0.7, list = F)
train_data <- df_fit[training_data, ]
test_data <- df_fit[-training_data, ]
```

## Step 4, model fitting
# model 1, bagging 
```{r}
set.seed(123)

#Set our value for mtry hyperparameter (the number of features eligible for selection at each node)

#Remember, in bagging, all predictor features are eligible for selection at each node
mtry_val1 <- expand.grid(.mtry = ncol(train_data)-1)

#Just setting 5-fold cross-validation for fast demonstration.
control_settings <- trainControl(method = "cv", number = 10, sampling = "up")

# model fit

model_fit_1 <- train(missing_sexid ~., data = train_data, method = "rf", metric = "Accuracy", 
                     tuneGrid = mtry_val1, ntree = 100, preProcess = c("center", "scale"), trControl = control_settings)

# visualization and accuracy
model_fit_1$results
model_fit_1$bestTune

varImp(model_fit_1)
plot(varImp(model_fit_1))
confusionMatrix(model_fit_1)

```

# model 2, Elastic Net method
```{r}
# model 2, chooses alpha and lambda via cross-validation using all of the features - Elastic Net method
set.seed(123)

# Construct k-folds in your data
trcontrol = trainControl(method = "cv", number = 10, sampling = "up")

# model 2 fit
model_fit_2 <- train(
  missing_sexid ~., data = train_data, method = "glmnet",
  trControl = trcontrol, preProc=c("center", "scale"), tuneLength = 10, metric = "Accuracy"
  )

# Print the values of alpha and lambda that gave best prediction
model_fit_2$bestTune

# Print all of the options examined
model_fit_2$results

# Model coefficients
coef(model_fit_2$finalModel, model_fit_2$bestTune$lambda)


# visualization and accuracy
varImp(model_fit_2)
plot(varImp(model_fit_2))
confusionMatrix(model_fit_2)
```

# model 3, random forest
```{r}
set.seed(123)
# Setting 5-fold cross-validation for fast demonstration.
control_settings<-trainControl(method = "cv", number = 10, sampling = "up")

# Trying three different values of mtry
mtry_vals_3 <- c(ncol(train_data)-1, sqrt(ncol(train_data)-1), 0.5*ncol(train_data)-1)
mtry_grid_3 <- expand.grid(.mtry = round(mtry_vals_3))

model_fit_3 <- train(
  missing_sexid ~., data = train_data, method = "rf", metric = "Accuracy",         
  preProc=c("center", "scale"), tuneGrid = mtry_grid_3, trControl = control_settings,  
  ntree=200
  )

confusionMatrix(model_fit_3)
model_fit_3$results
model_fit_3$bestTune
model_fit_3$finalModel

varImp(model_fit_3)
plot(varImp(model_fit_3))

# varImpPlot(model_fit_3$finalModel)
```

# model 4 boosting
```{r}
set.seed(123)

#First example where all hyperparameters are being held constant,  no cross-validation, using bootstrapping default

model_fit_boosting <- train(missing_sexid ~., data = train_data, method = "gbm", distribution = "bernoulli", verbose = F, tuneGrid = data.frame(.n.trees = 1000, .shrinkage = 0.001, .interaction.depth = 1, .n.minobsinnode = 10))

confusionMatrix(model_fit_boosting)
# varImp(model_fit_boosting)
#Second example where I tune hyperparameters
#set.seed(123)

#only running a few bootstrapped samples
#control.settings<-trainControl(number = 5)
#gbm.hyp <- expand.grid(n.trees = (0:10)*100, shrinkage = c(0.01, 0.001), interaction.depth = #c(1,3), n.minobsinnode = 10)

#model_fit_boosting_2 <- train(missing_sexid  ~., data = train_data, method = "gbm", #distribution = "bernoulli", verbose = F, tuneGrid = gbm.hyp, trControl = control.settings)

#confusionMatrix(model_fit_boosting_2)
# varImp(model_fit_boosting_2)
```


# Model 5 lasso
```{r}
# model 5, A lasso model using all of the features
# model 5 fit
set.seed(123)
lambda<-10^seq(-3,3, length=100)

# Construct k-folds in your data
trcontrol = trainControl(method = "CV", number = 10, sampling = "up")

model_fit_5 = train(missing_sexid ~., data = train_data, method = "glmnet", trControl = trcontrol, family = "binomial", tuneGrid = expand.grid(alpha = 1, lambda = lambda))

summary(model_fit_5)

confusionMatrix(model_fit_5)
```


# Model 5 classfication Tree model
```{r}
set.seed(123)

#Using 10-fold cross-validation to train model
train_control_tree <- trainControl(method = "cv", number = 10, sampling = "down")

#Create sequence of cp parameters to try 
grid_1 <- expand.grid(cp = seq(0.001, 0.3, by = 0.01))

#Using rpart method to generate regression tree, using all variables in dataset to predict life expectancy
model_fit_6 <- train(missing_sexid ~ . , data = train_data, method = "rpart", trControl = train_control_tree, tuneGrid = grid_1)

model_fit_6$bestTune
model_fit_6$results

#Can use rpart.plot function to visualize tree
rpart.plot(model_fit_6$finalModel)

#Note you can obtain variable importance on the final model within training data
varImp(model_fit_6)


confusionMatrix(model_fit_6)
```


## Step 5, Model evaluation and optimal model selection based on accuracy
```{r}
# Model 1
train_outcome_1 <- predict(model_fit_1, train_data)

model_train_eval_1 = confusionMatrix(train_outcome_1, train_data$missing_sexid, positive = "0")

# Model 2
train_outcome_2 <- predict(model_fit_2, train_data)

model_train_eval_2 = confusionMatrix(train_outcome_2, train_data$missing_sexid, positive = "0")

# Model 3
train_outcome_3 <- predict(model_fit_3, train_data)

model_train_eval_3 = confusionMatrix(train_outcome_3, train_data$missing_sexid, positive = "0")

# Model boosting
train_outcome_4 <- predict(model_fit_boosting, train_data)

model_train_eval_4 = confusionMatrix(train_outcome_4, train_data$missing_sexid, positive = "0")

# lasso
train_outcome_5 <- predict(model_fit_5, train_data)

model_train_eval_5 = confusionMatrix(train_outcome_5, train_data$missing_sexid, positive = "0")

# classfication Tree model
train_outcome_6 <- predict(model_fit_6, train_data)

model_train_eval_6 = confusionMatrix(train_outcome_6, train_data$missing_sexid, positive = "0")

model_train_eval_1
model_train_eval_2
model_train_eval_3
model_train_eval_4
model_train_eval_5
model_train_eval_6

compare_resamp <- resamples(list(
  bagging = model_fit_1,
  elastic_net = model_fit_2,
  random_forest = model_fit_3,
# boosting = mode_fit_4,
  lasso = model_fit_5,
  classification_tree = model_fit_6
))

summary(compare_resamp)
dotplot(compare_resamp)

# create table of accuracy and kappa
postResample(train_outcome_1, train_data$missing_sexid)
postResample(train_outcome_2, train_data$missing_sexid)
postResample(train_outcome_3, train_data$missing_sexid)
postResample(train_outcome_4, train_data$missing_sexid)
postResample(train_outcome_5, train_data$missing_sexid)
postResample(train_outcome_6, train_data$missing_sexid)

# All the evaluation parameters show that the performances of random forest model and bagging model are very close and better than the elastic net model. Based on Accuracy, the random forest model is slightly better. So the final choice of model is the random forest model.
```


## Step 6, the performance of final model within test dataset
```{r}
# Model 2, the final model - random forest model.
test_outcome_3 <- predict(model_fit_3, test_data)

model_eval_3 = confusionMatrix(test_outcome_3, test_data$missing_sexid, positive = "0")

model_eval_3

postResample(test_outcome_3, test_data$missing_sexid)

# Find the features that are most important for the prediction
varImp(model_fit_3)
plot(varImp(model_fit_3))

# varImpPlot(model_fit_3$finalModel)

# Based on the optimized model (random forest), the most important feature for the model includes:
# weight
# missing_qfoodallergy
# bmipct
# bmi
# shtight
```













